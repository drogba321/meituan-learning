##Storm介绍##

###Storm集群构成###

- Storm集群和Hadoop集群表面上看很类似。区别在于Hadoop上运行的是M/R Job，而Storm上运行的是Topology。并且M/R Job终究是会执行结束的，而Topology则会永远执行下去（流式计算）。
- Storm集群中有两种节点：**控制节点**（master node）和**工作节点**（worker node），很类似于hadoop中的管理节点（master node）与数据节点（data node）。
- **Nimbus**：运行于控制节点上的守护进程，类似于hadoop中的JobTracker。它负责在Storm集群中分发代码，分配计算任务给机器，监控集群状态。
- **SuperVisor**：运行于工作节点上的守护进程。它管理自己所在的工作节点上的**工作进程**。
- Nimbus和SuperVisor之间的协调工作都通过ZooKeeper来完成，并且Nimbus和SuperVisor都是无状态的，因此可以杀死它们再重启而没有任何状态丢失，从而保证集群非常稳定。
- **Topology**：是一个由**喷嘴（Spout）**和**螺栓（Bolt）**组成的**图**。一个运行的Topology由分布在多个机器上的多个工作进程组成。每个SuperVisor只管理自己所辖的工作节点上的工作进程，也就是Topology的一个子集。

###Topology###

- Topology是Storm流式计算的核心，它会一直运行直到手动kill掉。
- **消息流（Stream）**：Storm流式计算中的关键抽象，一个消息流是一个无边界的**元组（Tuple）**序列，也即消息流是由元组构成的，这些元组以分布式的方式被并行地创建并处理。
- **元组（Tuple）**：Storm中的数据模型。一个元组是一个包含多个值的命名列表，其中每个值可以是任意类型的对象。
- **喷嘴（Spout）**：Topology中的消息生产者，一般从外部数据源（例如Kafka）读取数据并向Topology中的其他组件（例如后续的Bolt）发射数据。Spout可以设置为可靠的或者不可靠的：可靠的Spout在其发射的Tuple没有被成功处理后会重新发射一次；不可靠的Spout则一旦发射出一个Tuple后就不会重复发射了。Spout中的重要方法如下：
	+ `nextTuple()`：发射新的Tuple（通过`SpoutOutputCollector.emit()`方法）。
	+ `ack()`：当一个Tuple被整个Topology成功处理后，会回调该方法。
	+ `fail()`：当一个Tuple未被整个Topology成功处理，则会回调该方法。注意，Storm只对可靠的Spout调用`ack()`和`fail()`方法。
	+ 以下是一个Spout的完整示例：
		
			public class RandomWordSpout extends BaseRichSpout {
			
  				SpoutOutputCollector _collector;
  				Random _rand;

				//执行Spout的初始化工作
  				@Override
  				public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
    				_collector = collector;
    				_rand = new Random();
  				}

				//发射新的Tuple，此处发射的是一个随机的单词
  				@Override
 				public void nextTuple() {
    				Utils.sleep(100);
    				String[] words = new String[]{ "apple","banana","orange","pear","melon" };
    				String word = words[_rand.nextInt(words.length)];
    				_collector.emit(new Values(word));
  				}

				//当发射的Tuple被整个Topology成功处理后，Storm会回调该方法
  				@Override
  				public void ack(Object msgId) {
  				}

				//当发射的Tuple处理失败后，Storm会得到通知并回调该方法
  				@Override
  				public void fail(Object msgId) {
  				}

				/*声明该Spout发射的Tuple格式，此处为一元Tuple，其唯一的Field名为"word"，
				其下游接收者调用tuple.getString(0)方法即可得到"word"域的值*/
  				@Override
  				public void declareOutputFields(OutputFieldsDeclarer declarer) {
    				declarer.declare(new Fields("word"));
  				}
			}
- **螺栓（Bolt）**：Topology中的消息处理者，所有的消息处理逻辑全都在Bolt中，例如过滤、聚合、计算、读写数据库等。Bolt接收上游的Spout或Bolt发射的Tuple，处理后可以发射（也可以不发射）新的Tuple供下游组件处理。Bolt中的重要方法如下：
	+ `prepare()`：在Bolt处理接收到的Tuple之前的准备工作，例如初始化变量、配置等。
	+ `execute()`：处理消息的核心方法，以一个Tuple作为输入。注意：Bolt必须要为它处理的每一个Tuple调用`OutputCollector.ack()`方法，以通知Storm这个Tuple被处理完成了，从而通知这个Tuple的发射者Spout。若Bolt不调用`ack()`或`fail()`方法确认处理成功或失败，则Storm就会一直追踪该Tuple，由于会占用内存，容易导致OutOfMemory错误。
	+ `cleanup()`：Bolt处理消息完成之后的清理工作。
	+ `declareOutputFields()`：声明该Bolt处理完输入Tuple后，输出的Tuple格式。
	+ 以下是一个Bolt的完整示例：

			public class ExclamationBolt implements IRichBolt {
		
    			OutputCollector _collector;

				//准备工作：初始化OutputCollector实例变量
				@Override
    			public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
        			_collector = collector;
    			}
			
				//处理元组：把输入Tuple加上"!!!"作为输出Tuple发射出去，然后调用OutputCollector.ack()方法通知Storm该Tuple已被处理
				@Override
    			public void execute(Tuple tuple) {
        			_collector.emit(tuple, new Values(tuple.getString(0) + "!!!"));
        			_collector.ack(tuple);
    			}
    		
				//清理工作
				@Override
    			public void cleanup() {
    			}

				//声明该Bolt输出Tuple的格式，此处声明的是一个一元Tuple，其唯一的Field名为"word"
				@Override
    			public void declareOutputFields(OutputFieldsDeclarer declarer) {
        			declarer.declare(new Fields("word"));
    			}
			}
			
- **Stream Grouping**：消息流的分组方式，用来定义消息流里的数据（Tuple）应当如何分配给Bolt的多个Task。常用的方式有以下几种：
	+ **Shuffle Grouping**：采用“混洗方式”随机分组，把数据大致平均地分配给Bolt的每个Task。
	+ **Fields Grouping**：按Tuple中的字段（Field）分组。例如按字段"word"分组，则字段"word"相同的Tuple会被Bolt的同一个Task所处理，字段"word"不同的Tuple会被Bolt的不同Task处理。在计算词频等情形下，使用这种分组方式可以确保每个出现多次的单词可以被同一个Task所处理，避免多算和漏算。
	+ **All Grouping**：广播分组，即Bolt的每一个Task都会收到每一个Tuple。
- **Topology**：一个完整的Topology示例如下：

		public static void main(String[] args) throws InterruptedException {  
		
        	/** 1.定义Topology */  
        	TopologyBuilder builder = new TopologyBuilder();
        	
        	//指定该Topology的喷嘴为WordReader，其id为"word-reader"
        	builder.setSpout("word-reader",new WordReader());  
        	
        	/*指定第一个螺栓为WordNormalizer，其id为"word-normalizer"，它接收"word-reader"发射的数据，
        	分组方式为Shuffle Grouping，即Tuple会被随机分配到该Bolt的各个Task（此处只有一个Task）*/
        	builder.setBolt("word-normalizer", new WordNormalizer())  
        				.shuffleGrouping("word-reader");  
        				
        	/*指定第二个螺栓为WordCounter，其id为"word-counter"，它接收"word-normalizer"发射的数据，
        	分组方式为Fields Grouping，即字段"word"值相同的Tuple会被分配到该Bolt的同一个Task处理
        	（此处指定了2个Task，即在Storm集群上有2个线程并行地执行该Bolt的任务）*/
        	builder.setBolt("word-counter", new WordCounter(), 2)  
        				.fieldsGrouping("word-normalizer", new Fields("word"));  
        				
        	/** 2.配置Topology */ 
        	Config conf = new Config();  
        	conf.put("wordsFile", "d:/text.txt");  
        	conf.setDebug(false);  
        	conf.put(Config.TOPOLOGY_MAX_SPOUT_PENDING, 1);  
        	
        	/** 3.创建一个本地模式的集群，并向该集群提交Topology */    
        	LocalCluster cluster = new LocalCluster();  
        	cluster.submitTopology("Getting-Started-Toplogie", conf, builder.createTopology());  
        	Thread.sleep(5000);  
        	
        	/** 4.终止该集群，结束Topology的运行 */
        	cluster.shutdown();  
    	}  