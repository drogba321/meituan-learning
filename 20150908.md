##Storm介绍##

###Storm集群构成###

- Storm集群和Hadoop集群表面上看很类似。区别在于Hadoop上运行的是M/R job，而Storm上运行的是Topology。并且M/R job终究是会执行结束的，而Topology则会永远执行下去（流式计算）。
- Storm集群中有两种节点：**控制节点**（master node）和**工作节点**（worker node），很类似于hadoop中的管理节点（master node）与数据节点（data node）。
- **Nimbus**：运行于控制节点上的守护进程，类似于hadoop中的JobTracker。它负责在Storm集群中分发代码，分配计算任务给机器，监控集群状态。
- **SuperVisor**：运行于工作节点上的守护进程。它管理自己所在的工作节点上的**工作进程**。
- Nimbus和SuperVisor之间的协调工作都通过ZooKeeper来完成，并且Nimbus和SuperVisor都是无状态的，因此可以杀死它们再重启而没有任何状态丢失，从而保证集群非常稳定。
- **Topology**：是一个由**喷嘴（Spout）**和**螺栓（Bolt）**组成的**图**。一个运行的Topology由分布在多个机器上的多个工作进程组成。每个SuperVisor只管理自己所辖的工作节点上的工作进程，也就是Topology的一个子集。

###Topology###

- Topology是Storm流式计算的核心，它会一直运行直到手动kill掉。
- **消息流（Stream）**：Storm流式计算中的关键抽象，一个消息流是一个无边界的**元组（Tuple）**序列，也即消息流是由元组构成的，这些元组以分布式的方式被并行地创建并处理。
- **元组（Tuple）**：Storm中的数据模型。一个元组是一个包含多个值的命名列表，其中每个值可以是任意类型的对象。
- **喷嘴（Spout）**：Topology中的消息生产者，一般从外部数据源（例如Kafka）读取数据并向Topology中的其他组件（例如后续的Bolt）发射数据。Spout可以设置为可靠的或者不可靠的：可靠的Spout在其发射的Tuple没有被成功处理后会重新发射一次；不可靠的Spout则一旦发射出一个Tuple后就不会重复发射了。Spout中的重要方法如下：
	+ `nextTuple()`：发射新的Tuple（通过`SpoutOutputCollector.emit()`方法）。
	+ `ack()`：当一个Tuple被整个Topology成功处理后，会回调该方法。
	+ `fail()`：当一个Tuple未被整个Topology成功处理，则会回调该方法。注意，Storm只对可靠的Spout调用`ack()`和`fail()`方法。
	+ 以下是一个Spout的完整示例：
		
			public class RandomWordSpout extends BaseRichSpout {
			
  				SpoutOutputCollector _collector;
  				Random _rand;

				//执行Spout的初始化工作
  				@Override
  				public void open(Map conf, TopologyContext context, SpoutOutputCollector collector) {
    				_collector = collector;
    				_rand = new Random();
  				}

				//发射新的Tuple，此处发射的是一个随机的单词
  				@Override
 				public void nextTuple() {
    				Utils.sleep(100);
    				String[] words = new String[]{ "apple","banana","orange","pear","melon" };
    				String word = words[_rand.nextInt(words.length)];
    				_collector.emit(new Values(word));
  				}

				//当发射的Tuple被整个Topology成功处理后，Storm会回调该方法
  				@Override
  				public void ack(Object id) {
  				}

				//当发射的Tuple处理失败后，Storm会得到通知并回调该方法
  				@Override
  				public void fail(Object id) {
  				}

				/*声明该Spout发射的Tuple格式，此处为一元Tuple，其唯一的Field名为"word"，
				其下游接收者调用tuple.getString(0)方法即可得到"word"域的值*/
  				@Override
  				public void declareOutputFields(OutputFieldsDeclarer declarer) {
    				declarer.declare(new Fields("word"));
  				}
			}
- **螺栓（Bolt）**：Topology中的消息处理者，所有的消息处理逻辑全都在Bolt中，例如过滤、聚合、计算、读写数据库等。Bolt接收上游的Spout或Bolt发射的Tuple，处理后可以发射（也可以不发射）新的Tuple供下游组件处理。Bolt中的重要方法如下：
	+ `prepare()`：在Bolt处理接收到的Tuple之前的准备工作，例如初始化变量、配置等。
	+ `execute()`：处理消息的核心方法，以一个Tuple作为输入。注意：Bolt必须要为它处理的每一个Tuple调用`OutputCollector.ack()`方法，以通知Storm这个Tuple被处理完成了，从而通知这个Tuple的发射者Spout。若Bolt不调用`ack()`或`fail()`方法确认处理成功或失败，则Storm就会一直追踪该Tuple，由于会占用内存，容易导致OutOfMemory错误。
	+ `cleanup()`：Bolt处理消息完成之后的清理工作。
	+ `declareOutputFields()`：声明该Bolt处理完输入Tuple后，输出的Tuple格式。
	+ 以下是一个Bolt的完整示例：

			public static class ExclamationBolt implements IRichBolt {
		
    			OutputCollector _collector;

				//准备工作：初始化OutputCollector实例变量
    			public void prepare(Map conf, TopologyContext context, OutputCollector collector) {
        			_collector = collector;
    			}
			
				//处理元组：把输入Tuple加上"!!!"作为输出Tuple发射出去，然后调用OutputCollector.ack()方法通知Storm该Tuple已被处理
    			public void execute(Tuple tuple) {
        			_collector.emit(tuple, new Values(tuple.getString(0) + "!!!"));
        			_collector.ack(tuple);
    			}
    		
				//清理工作
    			public void cleanup() {
    			}

				//声明该Bolt输出Tuple的格式，此处声明的是一个一元Tuple，其唯一的Field名为"word"
    			public void declareOutputFields(OutputFieldsDeclarer declarer) {
        			declarer.declare(new Fields("word"));
    			}
			}
			
- **Stream Grouping**：用来定义消息流里的数据（Tuple）应当如何分配给多个Bolt的多个task。常用的方式有以下几种：
	+ **Shuffle Grouping**：采用“混洗方式”随机分组，把数据大致平均地分配给每个Bolt。
	+ **Fields Grouping**：